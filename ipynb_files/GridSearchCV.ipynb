{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6156d917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90        66\n",
      "           1       0.91      0.97      0.94       105\n",
      "\n",
      "    accuracy                           0.92       171\n",
      "   macro avg       0.93      0.91      0.92       171\n",
      "weighted avg       0.93      0.92      0.92       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import all necessary libraries\n",
    "import sklearn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.datasets import load_breast_cancer \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split \n",
    " \n",
    "#load the dataset and split it into training and testing sets\n",
    "dataset = load_breast_cancer()\n",
    "X=dataset.data\n",
    "Y=dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "                        X,Y,test_size = 0.30, random_state = 101) \n",
    "# train the model on train set without using GridSearchCV \n",
    "model = SVC() \n",
    "model.fit(X_train, y_train) \n",
    "   \n",
    "# print prediction results \n",
    "predictions = model.predict(X_test) \n",
    "print(classification_report(y_test, predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8383d778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 56  10]\n",
      " [  3 102]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6ba7534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 30)\n",
      "(569,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(X_test.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ff648e",
   "metadata": {},
   "source": [
    "class sklearn.model_selection.GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af9e76a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "{'C': 100, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94        66\n",
      "           1       0.94      0.98      0.96       105\n",
      "\n",
      "    accuracy                           0.95       171\n",
      "   macro avg       0.96      0.95      0.95       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defining parameter range \n",
    "param_grid = {'C': [0.1,1,10, 100],  \n",
    "              #'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'gamma':['scale', 'auto'],\n",
    "              'kernel': ['linear']}  \n",
    "   \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True,cv =5, verbose = 3,n_jobs=-1) \n",
    "   \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train) \n",
    " \n",
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "grid_predictions = grid.predict(X_test) \n",
    "   \n",
    "# print classification report \n",
    "print(classification_report(y_test, grid_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04110383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 60   6]\n",
      " [  2 103]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,grid_predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b26c3d",
   "metadata": {},
   "source": [
    "##  u can also use\n",
    "\n",
    "from sklearn.utils.fixes import loguniform\n",
    "{'C': loguniform(1e0, 1e3),\n",
    " 'gamma': loguniform(1e-4, 1e-3),\n",
    " 'kernel': ['rbf'],\n",
    " 'class_weight':['balanced', None]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e79c8e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy\n",
    "random_grid = {'C': scipy.stats.expon(scale=100), 'gamma': scipy.stats.expon(scale=.1),\n",
    "  'kernel': ['linear'], 'class_weight':['balanced', None]}\n",
    "rf_random = RandomizedSearchCV(SVC(), param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)# Fit the random search model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e3e9c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "{'C': 93.533302064961, 'class_weight': 'balanced', 'gamma': 0.05987451438464722, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.94        66\n",
      "           1       0.94      0.99      0.96       105\n",
      "\n",
      "    accuracy                           0.95       171\n",
      "   macro avg       0.96      0.94      0.95       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fitting the model for grid search \n",
    "rf_random.fit(X_train, y_train) \n",
    " \n",
    "# print best parameter after tuning \n",
    "print(rf_random.best_params_) \n",
    "rf_random_predictions = rf_random.predict(X_test) \n",
    "   \n",
    "# print classification report \n",
    "print(classification_report(y_test, rf_random_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c31d564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 59   7]\n",
      " [  1 104]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, rf_random_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b2ef7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
